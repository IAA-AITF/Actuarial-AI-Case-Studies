<img src="logo.png" width="300px">

<br>
<p style="font-size:19px; text-align:left; margin-top: 15px; margin-bottom: 15px">IAA Task Force <i>Artificial Intelligence</i></p>
<p style="font-size:25px; text-align:left; margin-bottom: 25px"><b>Actuarial AI Case Studies</b></p>
<br>

| # | Date&nbsp;Added | Author | Title | Resource(s) | Type | Level | Primary&nbsp;Topics | Secondary&nbsp;Topics | Language(s) | Programming Language(s) | Methods&nbsp;and/or&nbsp;Models | AI&nbsp;Control Cycle | Notes | Abstract/Summary
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| 1 | 2024-05-08 | DAV&nbsp;üá©üá™ | Binary&nbsp;Classification: Credit&nbsp;Scoring | [Description](https://aktuar.de/en/knowledge/specialist-information/detail/forecasting-rare-events-credit-scoring/), <br> [Notebook](https://kaggle.com/code/floser/binary-classification-credit-scoring) | Case Study | üü®üü®‚¨ú <br> Advanced | `Machine Learning` `Classification` | `Explainable AI` `Hyperparameter Tuning` `GPU Usage` | English | Python | CatBoost, XGBoost, LightGBM, Deep Learning, Logarithmic Regression, SHAP | (?) | Data&nbsp;derived&nbsp;from&nbsp;a&nbsp;Kaggle competition's real-world dataset | This Jupyter Notebook offers a hands-on tutorial on binary classification using the Home Credit Default Risk dataset from Kaggle. Our focus is on predicting loan repayment difficulties, equipping actuaries with skills applicable to common insurance scenarios like churn prediction and fraud detection. Structured in three parts, the notebook progresses from simple to advanced modeling techniques: Part A sets a performance benchmark with an initial CatBoost model, a gradient boosting algorithm that requires minimal data preprocessing. Part B explores logistic regression, then delves into a brief exploratory data analysis, feature engineering, and model interpretability ‚Äì all essential for making informed decisions. We cover data preprocessing, including encoding, scaling, and subsampling for imbalanced data, and investigate the impact on modeling. Part C is devoted to the optimization and practical application of machine learning models. It first addresses overfitting using the example of regularized logistic regression, as well as hyperparameter tuning in artificial neural networks and gradient boosting methods CatBoost, LightGBM, and XGBoost. After a comprehensive model evaluation using validation and test data, we discuss application aspects in high-risk areas and conclude by summarizing the key insights we have learned. The appendix provides further information on CatBoost and GPU-accelerated training.
| 2 | 2024-05-08 | SAV&nbsp;üá®üá≠ | SHAP&nbsp;for&nbsp;Actuaries: Explain&nbsp;Any&nbsp;Model | [Article](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4389797), <br> [Notebook](https://github.com/actuarial-data-science/Tutorials/tree/master/14%20-%20SHAP) | Educational | üü®üü®‚¨ú <br> Advanced | `Explainable AI` `Interpretable ML` | `Regression` `Synthetic Data` `Claims Prediction` | English | Python, R | GLM, LightGBM, Deep Learning, SHAP | (?) | Data&nbsp;generation&nbsp;process&nbsp;and ground truth given | This&nbsp;tutorial&nbsp;gives&nbsp;an&nbsp;overview&nbsp;of&nbsp;SHAP&nbsp;(SHapley&nbsp;Additive&nbsp;exPlanation),&nbsp;one&nbsp;of&nbsp;the&nbsp;most&nbsp;commonly&nbsp;used&nbsp;techniques&nbsp;for&nbsp;examining&nbsp;a&nbsp;black‚Äëbox&nbsp;machine&nbsp;learning&nbsp;(ML)&nbsp;model.<br>Besides&nbsp;providing&nbsp;the&nbsp;necessary&nbsp;game&nbsp;theoretic&nbsp;background,&nbsp;we&nbsp;show&nbsp;how&nbsp;typical&nbsp;SHAP&nbsp;analyses&nbsp;are&nbsp;performed&nbsp;and&nbsp;used&nbsp;to&nbsp;gain&nbsp;insights&nbsp;about&nbsp;the&nbsp;model.<br>The&nbsp;methods&nbsp;are&nbsp;illustrated&nbsp;on&nbsp;a&nbsp;simulated&nbsp;insurance&nbsp;data&nbsp;set&nbsp;of&nbsp;car&nbsp;claim&nbsp;frequencies&nbsp;using&nbsp;different&nbsp;ML&nbsp;models&nbsp;and&nbsp;different&nbsp;SHAP&nbsp;algorithms.
| 3 | 2024-05-11 | Caesar&nbsp;Balona&nbsp;üáøüá¶ | Case&nbsp;Study&nbsp;1: Parsing&nbsp;Claims&nbsp;Descriptions | [Article](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwi_toXSoYWGAxXUVPEDHcPkAOI4ChAWegQICxAB&url=https%3A%2F%2Factuaries.org.uk%2Fmedia%2Fpurp2kk5%2Factuary-gpt-applications-of-large-language-models-to-insurance-and-actuarial-work.pdf&usg=AOvVaw1KRTDCIgv9IHZ5XlztvoWk&opi=89978449), <br> [Code](https://github.com/cbalona/actuarygpt-code/tree/main/case-study-1) | Case Study | üü®üü®‚¨ú <br> Advanced | `Large Language Models` | `Information Extraction` `Parsing` | English | Python | ChatGPT with GPT-4 | (?) | ‚Äì | In this case study, GPT-4 was employed to parse interactions with policyholders during the claims process to assess the sentiment of the engagement, the emotional state of the claimant, and inconsistencies in the claims information to aid downstream fraud investigations. It is important to emphasise that the LLM functions as an automation tool in this context and is not intended to supplant human claims handlers or serve as the ultimate arbiter in fraud detection or further engagements. Instead, it aims to support claims handlers by analyzing the information provided by the claimant, summarizing the engagement, and offering a set of indicators to inform subsequent work.
| 4 | 2024-05-11 | Caesar&nbsp;Balona&nbsp;üáøüá¶ | Case&nbsp;Study&nbsp;2: Identifying&nbsp;Emerging&nbsp;Risks | [Article](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwi_toXSoYWGAxXUVPEDHcPkAOI4ChAWegQICxAB&url=https%3A%2F%2Factuaries.org.uk%2Fmedia%2Fpurp2kk5%2Factuary-gpt-applications-of-large-language-models-to-insurance-and-actuarial-work.pdf&usg=AOvVaw1KRTDCIgv9IHZ5XlztvoWk&opi=89978449), <br> [Code](https://github.com/cbalona/actuarygpt-code/tree/main/case-study-2) | Case Study | üü©‚¨ú‚¨ú <br> Beginner | `Large Language Models` | `Text Generation` | English | Python | ChatGPT with GPT-4 | (?) | ‚Äì | In this case study, GPT-4 is tasked with summarising a collection of news snippets to identify emerging cyber risks. The script conducts an automated custom Google Search for recent articles using a list of search terms. It extracts the metadata of the search results and employs GPT-4 to generate a detailed summary of the notable emerging cyber risks, themes, and trends identified. Subsequently, GPT-4 is requested to produce a list of action points based on the summary. Each action point is then input into GPT-4 again to generate project plans for fulfilling the action points. This case study and its associated code demonstrate, at a basic level, the ease with which LLMs can be integrated directly into actuarial and insurance work, including additional prompting against its own output to accomplish further tasks.
| 5 | 2024-06-13 | Simon&nbsp;Hatzesberger&nbsp;üá©üá™ | Model-Agnostic Explainability Methods for Regression Problems: A Case Study on Medical Costs Data | see folder ['Case&nbsp;Study&nbsp;#5'](https://github.com/IAA-AI-DS-test/AI-Case-Studies-in-Actuarial-Science/tree/main/Case%20Study%20%235) in this repository | Educational | üü®üü®‚¨ú <br> Advanced | `Explainable AI` | `Machine Learning` `Regression` | English | Python | CatBoost, PDP, ALE, PFI, SHAP, LIME | (?) | ‚Äì | In this Jupyter notebook, we offer a comprehensive walkthrough for actuaries and data scientists on applying model-agnostic explainability methods to regression tasks, using a medical costs dataset as our case study. With the growing prevalence of modern black box machine learning models, which often lack the interpretability of classical statistical models, these explainability methods become increasingly important to ensure transparency and trust in predictive modeling. We illuminate both global methods ‚Äì such as global surrogate models, PDPs, ALE plots, and permutation feature importances ‚Äì for a thorough understanding of model behavior, and local methods ‚Äì like SHAP, LIME, and ICE plots ‚Äì for detailed insights into individual predictions. In addition to concise overviews of these methods, the notebook provides practical code examples that readers can easily adopt, offering a user-friendly introduction to explainable artificial intelligence.
| 6 | 2024-06-13 | Simon&nbsp;Hatzesberger&nbsp;üá©üá™ | Model-Agnostic Explainability Methods for Binary Classification Problems: A Case Study on Car Insurance Data | [Notebook](https://www.kaggle.com/code/simonhatzesberger/model-agnostic-xai-methods-for-classification) | Educational | üü®üü®‚¨ú <br> Advanced | `Explainable AI` | `Machine Learning` `Classification` | English | Python | CatBoost, PDP, ALE, PFI, SHAP, LIME, Counterfactual Explanations, Anchors | (?) | ‚Äì | In this Jupyter notebook, we offer a comprehensive walkthrough for actuaries and data scientists on applying model-agnostic explainability methods to binary classification tasks, using a car insurance dataset as our case study. With the growing prevalence of modern black box machine learning models, which often lack the interpretability of classical statistical models, these explainability methods become increasingly important to ensure transparency and trust in predictive modeling. We illuminate both global methods ‚Äì such as global surrogate models, PDPs, ALE plots, and permutation feature importances ‚Äì for a thorough understanding of model behavior, and local methods ‚Äì like SHAP, LIME, ICE plots, counterfactual explanations, and anchors ‚Äì for detailed insights on individual predictions. In addition to concise overviews of these methods, the notebook provides practical code examples that readers can easily adopt, offering a user-friendly introduction to explainable artificial intelligence.
| 7 | 2024-07-16 | MAS (Monetary Authority of Singapore) üá∏üá¨ | FEAT Principles Assessment Case Studies | [Website](https://www.mas.gov.sg/news/media-releases/2022/mas-led-industry-consortium-publishes-assessment-methodologies-for-responsible-use-of-ai-by-financial-institutions), <br> [White Paper](https://www.mas.gov.sg/-/media/mas-media-library/news/media-releases/2022/veritas-document-4---feat-principles-assessment-case-studies.pdf) | Case Study | üü©‚¨ú‚¨ú <br> Beginner | `Fairness` `Ethics` `Accountability` `Transparency` | `Life Insurance Underwriting` `Fraud Detection` `Retail Marketing` `Credit Decisioning` `Customer Marketing` | English | ‚Äì | Gradient Boosting Model, PDP, SHAP, PFI | (?) | Data&nbsp;derived&nbsp;from&nbsp;a&nbsp;Kaggle competition's real-world dataset | This document is one of a suite of documents published as an output of the Monetary Authority of Singapore (MAS) Veritas Phase 2 project. Its purpose is to illustrate implementation of the Fairness, Ethics, Accountability and Transparency (FEAT) Principles Assessment Methodology for Financial Institutions on selected use cases and it fits alongside the published documents as highlighted in the diagram below.
| 8 | 2024-07-16 | Personal Data Protection Commission üá∏üá¨ | Compendium of Use Cases: Practical Illustrations of the Model AI Governance Framework | [Website](https://www.pdpc.gov.sg/help-and-resources/2020/01/model-ai-governance-framework/), <br> [White Paper (Volume 1)](https://go.gov.sg/ai-gov-use-cases), <br> [White Paper (Volume 2)](https://go.gov.sg/ai-gov-use-cases-2) | Case Study | üü©‚¨ú‚¨ú <br> Beginner | `Governance` | TODO | English | ‚Äì | Gradient Boosting Model, PDP, SHAP, PFI | (?) | Data&nbsp;derived&nbsp;from&nbsp;a&nbsp;Kaggle competition's real-world dataset | AI will transform businesses and power the next bound of economic growth. Businesses and society can enjoy the full benefits of AI if the deployment of AI products and services is founded upon trustworthy AI governance practices. As part of advancing Singapore‚Äôs thought leadership in AI governance, Singapore has released the Model AI Governance Framework (Model Framework) to guide organisations on how to deploy AI in a responsible manner. This Compendium of Use Cases demonstrates how various organisations across different sectors ‚Äì big and small, local and international ‚Äì have either implemented or aligned their AI governance practices with all sections of the Model Framework. The Compendium also illustrates how the organisations have effectively put in place accountable AI governance practices and benefit from the use of AI in their line of business. By implementing responsible AI governance practices, organisations can distinguish themselves from others and show that they care about building trust with consumers and other stakeholders. This will create a virtuous cycle of trust, allowing organisations to continue to innovate for their stakeholders. We thank the World Economic Forum Centre for the Fourth Industrial Revolution for partnering us on this journey. We hope that this Compendium will inspire more organisations to embark on a similar journey. 
| 9 | 2024-07-16 | SAV&nbsp;üá®üá≠ (Andreas Troxler, J√ºrg Schelldorfer) | Actuarial Applications of Natural Language Processing Using Transformers | [Article](https://arxiv.org/pdf/2206.02014), <br> [Notebook](https://github.com/actuarial-data-science/Tutorials/tree/master/12%20-%20NLP%20Using%20Transformers) | Educational | üü•üü•üü• <br> Expert | `Natural Language Processing` `Transformers` | `Property Insurance Claims Descriptions` `Recurrent Neural Networks` | English | Python | Transformers, Recurrent Neural Networks, Integrated Gradients | (?) | ‚Äì | This tutorial demonstrates workflows to incorporate text data into actuarial classification and regression tasks. The main focus is on methods employing transformer-based models. A dataset of car accident descriptions with an average length of 400 words, available in English and German, and a dataset with short property insurance claims descriptions are used to demonstrate these techniques. The case studies tackle challenges related to a multi-lingual setting and long input sequences. They also show ways to interpret model output, to assess and improve model performance, by fine-tuning the models to the domain of application or to a specific prediction task. Finally, the tutorial provides practical approaches to handle classification tasks in situations with no or only few labeled data, including but not limited to ChatGPT. The results achieved by using the language-understanding skills of off-the-shelf natural language processing (NLP) models with only minimal pre-processing and fine-tuning clearly demonstrate the power of transfer learning for practical applications. |
| 10 | 2024-09-12 | SOA&nbsp;üá∫üá∏ (Logan T. Smith, Emma Pirchalski, Ilana Golbin) | Avoiding Unfair Bias in Insurance Applications of AI Models | [Website](https://www.soa.org/resources/research-reports/2022/avoid-unfair-bias-ai/), <br> [White Paper (English)](https://www.soa.org/4a288a/globalassets/assets/files/resources/research-report/2022/avoid-unfair-bias-ai.pdf), <br> [White Paper (Simplified Chinese)](https://www.soa.org/4959c4/globalassets/assets/files/resources/research-report/2023/avoid-unfair-bias-ai-chinese.pdf) | TODO | üü©‚¨ú‚¨ú <br> Beginner | `Bias` `Fairness` `Ethics` | ‚Äì | English, (Simplified) Chinese | ‚Äì | ‚Äì | ‚Äì | ‚Äì | Artificial intelligence (‚ÄúAI‚Äù) adoption in the insurance industry is increasing. One known risk as adoption of AI increases is the potential for unfair bias. Central to understanding where and how unfair bias may occur in AI systems is defining what unfair bias means and what constitutes fairness. This research identifies methods to avoid or mitigate unfair bias unintentionally caused or exacerbated by the use of AI models and proposes a potential framework for insurance carriers to consider when looking to identify and reduce unfair bias in their AI models. The proposed approach includes five foundational principles as well as a four-part model development framework with five stage gates.
| 11 | 2024-09-12 | SAV&nbsp;üá®üá≠ (Simon Rentzmann, Mario V. W√ºthrich) | Unsupervised Learning: What is a Sports Car? | [Article](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3439358), <br> [Notebook](https://github.com/actuarial-data-science/Tutorials/tree/master/5%20-%20Unsupervised%20Learning%20What%20is%20a%20Sports%20Car) | Educational | üü•üü•üü• <br> Expert | `Unsupervised Learning` | `Dimension Reduction` `Clustering` `Low Dimensional Visualization` | English | R | Principal Component Analysis (PCA), Bottleneck Neural Network, k-Means, k-Mediods, Gaussian Mixture Models, t-SNE, UMAP, SOM | (?) | ‚Äì | This tutorial studies unsupervised learning methods. Unsupervised learning methods are techniques that aim at reducing the dimension of data (covariables, features), cluster cases with similar features, and graphically illustrate high dimensional data. These techniques do not consider response variables, but they are solely based on the features themselves by studying incorporated similarities. For this reason, these methods belong to the field of unsupervised learning methods. The methods studied in this tutorial comprise principal components analysis (PCA) and bottleneck neural networks (BNNs) for dimension reduction, K-means clustering, K-medoids clustering, partitioning around medoids (PAM) algorithm and clustering with Gaussian mixture models (GMMs) for clustering, and variational autoencoder (VAE), t-distributed stochastic neighbor embedding (t-SNE), uniform manifold approximation and projection (UMAP), self-organizing maps (SOM) and Kohonen maps for visualizing high dimensional data. |
| 12 | 2025-05-11 | Simon Hatzesberger, Iris Nonneman | Car Damage Classification and Localization with Fine-Tuned Vision-Enabled LLMs | [README](https://github.com/IAA-AITF/Actuarial-AI-Case-Studies/tree/main/case-studies/2025/car_damage_classification_and_localization), <br> [Notebook](https://github.com/IAA-AITF/Actuarial-AI-Case-Studies/blob/main/case-studies/2025/car_damage_classification_and_localization/car_damage_classification_and_localization.ipynb) | Case Study | üü®üü®‚¨ú <br> Advanced | `Large Language Models`, `Fine-Tuning` | `Multiclass Classification` | English | Python | Convolutional Neural Network, GPT-4o | (?) | ‚Äì | This case study explores how Large Language Models can improve both the classification and contextual understanding of car damage from images ‚Äì an important task in automotive insurance, particularly for claims processing and risk assessment. Traditional computer vision methods, such as Convolutional Neural Networks (CNNs), have demonstrated strong performance in static image classification. However, these models often struggle to additionally incorporate contextual information that is valueable for insurance applications, such as precisely localizing damage, evaluating its severity, and accounting for external factors such as lighting and weather conditions at the time of capture. To address these limitations, we employ OpenAI's GPT-4o, a vision-enabled Large Language Model that integrates image recognition with natural language understanding. By fine-tuning this model on a domain-specific dataset of labeled car damage images, we achieve classification performance that is comparable to traditional models while also providing richer contextual insights. This enhanced capability allows the model to distinguish, for example, between minor glass damage on a side window and a fully shattered windshield. Beyond car damage analysis, this approach demonstrates broad applicability across various visual tasks in insurance. Its flexibility extends to medical image analysis, fraud detection in claims and invoices, and roof damage assessment in household and commercial property insurance, among others. Notably, the INS-MMbench dataset provides a diverse collection of images covering these and other insurance-related tasks. |
| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |

*Notes:*
- *The dates are formatted in ISO 8601 standard (*`YYYY-MM-DD`*).*
- *The "Author" column incorporates both the individual author and the member association.*
- *The "Resource(s)" column provides direct links to articles and code repositories.*
